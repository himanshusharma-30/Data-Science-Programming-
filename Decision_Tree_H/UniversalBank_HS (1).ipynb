{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c8a3d2",
   "metadata": {},
   "source": [
    "# UniversalBank (Target = CD Account)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bafc6f2",
   "metadata": {},
   "source": [
    "## 1.0 Setup : Import and install python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bd4b523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set random seed to ensure that results are repeatable\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdc090d",
   "metadata": {},
   "source": [
    "## 2.0 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f9c5475d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "UniversalBank = pd.read_csv(\"UniversalBank.csv\")\n",
    "\n",
    "# look at the data\n",
    "UniversalBank.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f53f9a8",
   "metadata": {},
   "source": [
    "## 3.0 Data Pocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bda160",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "1. ID and the ZIP Code columns will be dropped as part of feature selection and it is not needed\n",
    "2. We dont have any observations with missing NA's.\n",
    "3. Education we will encode it with Dummy encoding technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "28f37048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                    0\n",
       "Age                   0\n",
       "Experience            0\n",
       "Income                0\n",
       "ZIP Code              0\n",
       "Family                0\n",
       "CCAvg                 0\n",
       "Education             0\n",
       "Mortgage              0\n",
       "Personal Loan         0\n",
       "Securities Account    0\n",
       "CD Account            0\n",
       "Online                0\n",
       "CreditCard            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the missing values by summing the total na's for each variable\n",
    "UniversalBank.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "215934d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of these catagorical variables\n",
    "category_var_list = list(UniversalBank.select_dtypes(include='object').columns)\n",
    "category_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7115ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "UniversalBank.drop(['ID','ZIP Code'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094851ac",
   "metadata": {},
   "source": [
    "### Non ordered Dummy encoding\n",
    "As education is label encoded we need to change it to dummy encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "48f363dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "UniversalBank = UniversalBank.join(pd.get_dummies(UniversalBank['Education'],prefix='Education',drop_first = True))\n",
    "UniversalBank.drop('Education', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ee90a",
   "metadata": {},
   "source": [
    "## 4.0 Split Data\n",
    "Splitting the data into train and test, with traning set as 70% and test set as 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5a98d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into validation and training set\n",
    "train_df, test_df = train_test_split(UniversalBank, test_size=0.3)\n",
    "\n",
    "# to reduce repetition in later code, create variables to represent the columns\n",
    "# that are our predictors and target\n",
    "target = 'CD Account'\n",
    "predictors = list(UniversalBank.columns)\n",
    "predictors.remove(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeb0cae",
   "metadata": {},
   "source": [
    "#### Standardize numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "02718677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a standard scaler and fit it to the training set of predictors\n",
    "scaler = preprocessing.StandardScaler()\n",
    "cols_to_stdize = ['Age','Experience','Income','Family','CCAvg','Mortgage']\n",
    "               \n",
    "# Transform the predictors of training and validation sets\n",
    "train_df[cols_to_stdize] = scaler.fit_transform(train_df[cols_to_stdize]) # train_predictors is not a numpy array\n",
    "test_df[cols_to_stdize] = scaler.transform(test_df[cols_to_stdize]) # validation_target is now a series object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3c566167",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[predictors]\n",
    "y_train = train_df[target] # train_target is now a series objecttrain_df.to_csv('airbnb_train_df.csv', index=False)\n",
    "X_test = test_df[predictors]\n",
    "y_test = test_df[target] # validation_target is now a series object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6386e4",
   "metadata": {},
   "source": [
    "## 5.0 Model the data\n",
    "Create a dataframe to load the model performance metrics into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "241f4f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4d0fad",
   "metadata": {},
   "source": [
    "### 5.1 Logistic Regression using default,L1,L2,Elastic,liblinear regularization\n",
    "\n",
    "Conduting a random and exhaustive search across a smaller range of parameters around the parameters. We will use the value of best parameters found through Random Search to perform the Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "af93b075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.6335365853658537\n",
      "... with parameters: {'solver': 'saga', 'penalty': 'l1', 'max_iter': 649}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'max_iter':np.arange(500,1000),\n",
    "    'penalty': ['None','l1','l2','elasticnet'],\n",
    "    'solver':['saga','liblinear']\n",
    "}\n",
    "\n",
    "log_reg_model = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator = log_reg_model, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b02116d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "The best recall score is 0.6335365853658537\n",
      "... with parameters: {'max_iter': 646, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "max_iter = rand_search.best_params_['max_iter']\n",
    "penalty = rand_search.best_params_['penalty']\n",
    "solver = rand_search.best_params_['solver']\n",
    "\n",
    "param_grid = {\n",
    "    'max_iter': np.arange(max_iter-3,max_iter+3),  \n",
    "    'penalty': [penalty],\n",
    "    'solver': [solver]\n",
    "}\n",
    "\n",
    "log_reg_model = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = log_reg_model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallLogistic = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bf3540bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14498e8",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "For the Logistic Regression Classifier the best performing parameters are {'max_iter': 646, 'penalty': 'l1', 'solver': 'saga'} with the best recall score of 63.35%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17544c3",
   "metadata": {},
   "source": [
    "### 5.2 SVM Classification using linear, rbf and poly kernal\n",
    "\n",
    "Conduting a random and exhaustive search across a smaller range of parameters around the parameters. We will use the value of best parameters found through Random Search to perform the Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8e1f4c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 174 candidates, totalling 870 fits\n",
      "The best recall score is 0.6335365853658537\n",
      "... with parameters: {'kernel': 'linear', 'gamma': 'scale', 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(1,30),   \n",
    "    'gamma': ['scale','auto'],\n",
    "    'kernel':['linear','rbf','poly']\n",
    "}\n",
    "\n",
    "svm_model = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = svm_model, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "af967b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "The best recall score is 0.6335365853658537\n",
      "... with parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "C = rand_search.best_params_['C']\n",
    "gamma = rand_search.best_params_['gamma']\n",
    "kernel = rand_search.best_params_['kernel']\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(C-2,C+2),  \n",
    "    'gamma': [gamma],\n",
    "    'kernel': [kernel]\n",
    "    \n",
    "}\n",
    "\n",
    "svm_model = SVC()\n",
    "grid_search = GridSearchCV(estimator = svm_model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallSVM = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "efea8a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685bd201",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "For the SVM Classifier the best performing parameters are {'C': 1, 'gamma': 'scale', 'kernel': 'linear'} with the best recall score of 63.35%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ce1418",
   "metadata": {},
   "source": [
    "### 5.3  Decision Tree Classifier\n",
    "Conduting a random and exhaustive search across a smaller range of parameters. We will use the value of best parameters found through Random Search to perform the Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9481fe30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.6485365853658537\n",
      "... with parameters: {'min_samples_split': 17, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0006000000000000001, 'max_leaf_nodes': 49, 'max_depth': 45, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,100),  \n",
    "    'min_samples_leaf': np.arange(1,100),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 100), \n",
    "    'max_depth': np.arange(1,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "964fae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1728 candidates, totalling 8640 fits\n",
      "The best recall score is 0.6485365853658537\n",
      "... with parameters: {'min_samples_split': 17, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0006000000000000001, 'max_leaf_nodes': 49, 'max_depth': 45, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "min_samples_split = rand_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = rand_search.best_params_['min_samples_leaf']\n",
    "min_impurity_decrease = rand_search.best_params_['min_impurity_decrease']\n",
    "max_leaf_nodes = rand_search.best_params_['max_leaf_nodes']\n",
    "max_depth = rand_search.best_params_['max_depth']\n",
    "criterion = rand_search.best_params_['criterion']\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(min_samples_split-3,min_samples_split+3),  \n",
    "    'min_samples_leaf': np.arange(min_samples_leaf-3,min_samples_leaf+3),\n",
    "    'min_impurity_decrease': np.arange(min_impurity_decrease-0.0001, min_impurity_decrease+0.0001, 0.0001),\n",
    "    'max_leaf_nodes': np.arange(max_leaf_nodes-2,max_leaf_nodes+2), \n",
    "    'max_depth': np.arange(max_depth-2,max_depth+2), \n",
    "    'criterion': [criterion]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=dtree, param_grid=param_grid, cv=kfolds, scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ed5a23a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691664ca",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "For the Decision Tree Classifier the best performing parameters are {'min_samples_split': 17, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0006000000000000001, 'max_leaf_nodes': 49, 'max_depth': 45, 'criterion': 'entropy'} with the best recall score of 64.85%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2cf202",
   "metadata": {},
   "source": [
    "## 6.0 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "aa72861c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.784091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  Accuracy  Precision  Recall        F1\n",
       "0       Logistic  0.978667   1.000000    0.68  0.809524\n",
       "0            SVM  0.978667   1.000000    0.68  0.809524\n",
       "0  Decision Tree  0.974667   0.907895    0.69  0.784091"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=['Recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0ca6b0",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "Considering the three models, for scoring measure recall, we can see that Decision Tree has the best recall rate of 69%. \n",
    "The SVM and Logistics model has a recall rate of 68%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
